{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So1eqTqLT9HX",
        "outputId": "43761ff8-1b38-4374-afd4-a6fa093b3dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'latent-diffusion'...\n",
            "remote: Enumerating objects: 282, done.\u001b[K\n",
            "remote: Total 282 (delta 0), reused 0 (delta 0), pack-reused 282\u001b[K\n",
            "Receiving objects: 100% (282/282), 28.39 MiB | 8.83 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pkulwj1994/latent-diffusion.git\n",
        "!cp -a /content/latent-diffusion/. /content/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtF-H9zD4UPo",
        "outputId": "fc509f89-8b61-4378-bc72-891c89f88995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-22 12:17:05--  https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt\n",
            "Resolving ommer-lab.com (ommer-lab.com)... 141.84.41.65\n",
            "Connecting to ommer-lab.com (ommer-lab.com)|141.84.41.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6152314307 (5.7G)\n",
            "Saving to: ‘models/ldm/text2img-large/model.ckpt’\n",
            "\n",
            "models/ldm/text2img  73%[=============>      ]   4.22G   130MB/s    in 34s     \n",
            "\n",
            "2022-05-22 12:17:39 (126 MB/s) - Connection closed at byte 4527210496. Retrying.\n",
            "\n",
            "--2022-05-22 12:17:40--  (try: 2)  https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt\n",
            "Connecting to ommer-lab.com (ommer-lab.com)|141.84.41.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 6152314307 (5.7G), 1625103811 (1.5G) remaining\n",
            "Saving to: ‘models/ldm/text2img-large/model.ckpt’\n",
            "\n",
            "ext2img-large/model  82%[++++++++++++++=>    ]   4.75G   128MB/s    eta 9s     "
          ]
        }
      ],
      "source": [
        "!mkdir -p models/ldm/text2img-large/\n",
        "!wget -O models/ldm/text2img-large/model.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf\n",
        "!pip install einops\n",
        "!pip uninstall ldm\n",
        "!pip install pytorch_lightning\n",
        "!pip install fvcore==0.1.5.post20210924\n",
        "!pip install .\n",
        "!pip install transformers==4.3.1\n",
        "# !pip install ldm\n",
        "# !export PYTHONPATH=$PYTHONPATH:$(pwd)\n",
        "\n",
        "# !git clone https://github.com/CompVis/taming-transformers.git\n",
        "# %cd taming-transformers\n",
        "# !pip install .\n",
        "# %cd ..\n",
        "!pip install taming-transformers\n",
        "\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "%cd CLIP\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!git clone https://github.com/CompVis/taming-transformers.git\n",
        "%cd taming-transformers\n",
        "!pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwcMqCr29VVQ",
        "outputId": "5d0a0428-85b6-487f-8f7a-2e3c028cd3a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (2.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "\u001b[33mWARNING: Skipping ldm as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.2.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.8.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Requirement already satisfied: fvcore==0.1.5.post20210924 in /usr/local/lib/python3.7/dist-packages (0.1.5.post20210924)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (6.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (0.1.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (1.21.6)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (0.1.9)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5.post20210924) (0.8.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore==0.1.5.post20210924) (2.4.0)\n",
            "Processing /content\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from latent-diffusion==0.0.1) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->latent-diffusion==0.0.1) (4.2.0)\n",
            "Building wheels for collected packages: latent-diffusion\n",
            "  Building wheel for latent-diffusion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for latent-diffusion: filename=latent_diffusion-0.0.1-py3-none-any.whl size=1950 sha256=ac3043b8782a6071de87d63eb69a770e5387b844f7f2ca1c16a45a24355f9051\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-012ij4ve/wheels/63/0e/3b/c99faf0b2fc9bcbb6d311ff482288076f10040d8aef364be10\n",
            "Successfully built latent-diffusion\n",
            "Installing collected packages: latent-diffusion\n",
            "  Attempting uninstall: latent-diffusion\n",
            "    Found existing installation: latent-diffusion 0.0.1\n",
            "    Uninstalling latent-diffusion-0.0.1:\n",
            "      Successfully uninstalled latent-diffusion-0.0.1\n",
            "Successfully installed latent-diffusion-0.0.1\n",
            "Collecting transformers==4.3.1\n",
            "  Downloading transformers-4.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.1) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.1) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.1) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.1) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a9e668852f031990a50dd17fcfe0d0775f0fbe16c79303b676baab926709a922\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.3.1\n",
            "Requirement already satisfied: taming-transformers in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from taming-transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->taming-transformers) (4.2.0)\n",
            "fatal: destination path 'CLIP' already exists and is not an empty directory.\n",
            "/content/CLIP\n",
            "Processing /content/CLIP\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.12.0+cu113)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (1.24.3)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369387 sha256=9785508679ab7247c56f8c20df47d53a01f910f4f57c3c6eb345fecfa2a2364c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t6b8x1rg/wheels/9e/b0/5b/75abd9d449df0da019011d4fdb3b97be5d91eba3bd489460f9\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "  Attempting uninstall: clip\n",
            "    Found existing installation: clip 1.0\n",
            "    Uninstalling clip-1.0:\n",
            "      Successfully uninstalled clip-1.0\n",
            "Successfully installed clip-1.0\n",
            "/content\n",
            "fatal: destination path 'taming-transformers' already exists and is not an empty directory.\n",
            "/content/taming-transformers\n",
            "Processing /content/taming-transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->taming-transformers==0.0.1) (4.2.0)\n",
            "Building wheels for collected packages: taming-transformers\n",
            "  Building wheel for taming-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for taming-transformers: filename=taming_transformers-0.0.1-py3-none-any.whl size=1147 sha256=a244a02b7be8d2a8ac1c773a1c610a159dd0bf80112a8c6944e75d17fb58002f\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/1c/1e/107623d53b06b7b27712df36d729579a955d661f1817dfe311\n",
            "Successfully built taming-transformers\n",
            "Installing collected packages: taming-transformers\n",
            "  Attempting uninstall: taming-transformers\n",
            "    Found existing installation: taming-transformers 0.0.1\n",
            "    Uninstalling taming-transformers-0.0.1:\n",
            "      Successfully uninstalled taming-transformers-0.0.1\n",
            "Successfully installed taming-transformers-0.0.1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -a taming-transformers/taming taming"
      ],
      "metadata": {
        "id": "e8p_4dHW10Rj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bFWTxzZe4USJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec113b7-1dae-490f-aed4-134e13c49363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from models/ldm/text2img-large/model.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 872.30 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!cp scripts/txt2img.py txt2img.py\n",
        "!python txt2img.py --prompt \"a virus monster is playing guitar, oil on canvas\" --ddim_eta 0.0 --n_samples 4 --n_iter 4 --scale 5.0  --ddim_steps 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QP1vC1GR4UUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0caf7188-e6a9-45e6-9ea9-a528ad5a3bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from models/ldm/text2img-large/model.ckpt\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 872.30 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rSampling:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (4, 4, 32, 32), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:29,  1.65it/s]\u001b[A\n",
            "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:16,  2.89it/s]\u001b[A\n",
            "DDIM Sampler:   6%|▌         | 3/50 [00:00<00:12,  3.83it/s]\u001b[A\n",
            "DDIM Sampler:   8%|▊         | 4/50 [00:01<00:10,  4.33it/s]\u001b[A\n",
            "DDIM Sampler:  10%|█         | 5/50 [00:01<00:09,  4.82it/s]\u001b[A\n",
            "DDIM Sampler:  12%|█▏        | 6/50 [00:01<00:08,  5.21it/s]\u001b[A\n",
            "DDIM Sampler:  14%|█▍        | 7/50 [00:01<00:07,  5.52it/s]\u001b[A\n",
            "DDIM Sampler:  16%|█▌        | 8/50 [00:01<00:07,  5.74it/s]\u001b[A\n",
            "DDIM Sampler:  18%|█▊        | 9/50 [00:01<00:06,  5.91it/s]\u001b[A\n",
            "DDIM Sampler:  20%|██        | 10/50 [00:02<00:06,  6.04it/s]\u001b[A\n",
            "DDIM Sampler:  22%|██▏       | 11/50 [00:02<00:06,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  24%|██▍       | 12/50 [00:02<00:06,  6.16it/s]\u001b[A\n",
            "DDIM Sampler:  26%|██▌       | 13/50 [00:02<00:05,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  28%|██▊       | 14/50 [00:02<00:05,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  30%|███       | 15/50 [00:02<00:05,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  32%|███▏      | 16/50 [00:03<00:05,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  34%|███▍      | 17/50 [00:03<00:05,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  36%|███▌      | 18/50 [00:03<00:05,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  38%|███▊      | 19/50 [00:03<00:04,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  40%|████      | 20/50 [00:03<00:04,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  42%|████▏     | 21/50 [00:03<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  44%|████▍     | 22/50 [00:03<00:04,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  46%|████▌     | 23/50 [00:04<00:04,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  48%|████▊     | 24/50 [00:04<00:04,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  50%|█████     | 25/50 [00:04<00:03,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  52%|█████▏    | 26/50 [00:04<00:03,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  54%|█████▍    | 27/50 [00:04<00:03,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  56%|█████▌    | 28/50 [00:04<00:03,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  58%|█████▊    | 29/50 [00:05<00:03,  6.31it/s]\u001b[A\n",
            "DDIM Sampler:  60%|██████    | 30/50 [00:05<00:03,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  62%|██████▏   | 31/50 [00:05<00:03,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  64%|██████▍   | 32/50 [00:05<00:02,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  66%|██████▌   | 33/50 [00:05<00:02,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  68%|██████▊   | 34/50 [00:05<00:02,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  70%|███████   | 35/50 [00:06<00:02,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  72%|███████▏  | 36/50 [00:06<00:02,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  74%|███████▍  | 37/50 [00:06<00:02,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  76%|███████▌  | 38/50 [00:06<00:01,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  78%|███████▊  | 39/50 [00:06<00:01,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  80%|████████  | 40/50 [00:06<00:01,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  82%|████████▏ | 41/50 [00:07<00:01,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  84%|████████▍ | 42/50 [00:07<00:01,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  86%|████████▌ | 43/50 [00:07<00:01,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  88%|████████▊ | 44/50 [00:07<00:00,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  90%|█████████ | 45/50 [00:07<00:00,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  92%|█████████▏| 46/50 [00:07<00:00,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  94%|█████████▍| 47/50 [00:07<00:00,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  96%|█████████▌| 48/50 [00:08<00:00,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  98%|█████████▊| 49/50 [00:08<00:00,  6.26it/s]\u001b[A\n",
            "DDIM Sampler: 100%|██████████| 50/50 [00:08<00:00,  5.91it/s]\n",
            "Sampling:  25%|██▌       | 1/4 [00:08<00:26,  8.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (4, 4, 32, 32), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:07,  6.48it/s]\u001b[A\n",
            "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:07,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:   6%|▌         | 3/50 [00:00<00:07,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:   8%|▊         | 4/50 [00:00<00:07,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  10%|█         | 5/50 [00:00<00:07,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  12%|█▏        | 6/50 [00:00<00:07,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  14%|█▍        | 7/50 [00:01<00:06,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  16%|█▌        | 8/50 [00:01<00:06,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  18%|█▊        | 9/50 [00:01<00:06,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  20%|██        | 10/50 [00:01<00:06,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  22%|██▏       | 11/50 [00:01<00:06,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  24%|██▍       | 12/50 [00:01<00:06,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  26%|██▌       | 13/50 [00:02<00:05,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  28%|██▊       | 14/50 [00:02<00:05,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  30%|███       | 15/50 [00:02<00:05,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  32%|███▏      | 16/50 [00:02<00:05,  5.81it/s]\u001b[A\n",
            "DDIM Sampler:  34%|███▍      | 17/50 [00:02<00:05,  5.92it/s]\u001b[A\n",
            "DDIM Sampler:  36%|███▌      | 18/50 [00:02<00:05,  5.99it/s]\u001b[A\n",
            "DDIM Sampler:  38%|███▊      | 19/50 [00:03<00:05,  6.04it/s]\u001b[A\n",
            "DDIM Sampler:  40%|████      | 20/50 [00:03<00:05,  5.38it/s]\u001b[A\n",
            "DDIM Sampler:  42%|████▏     | 21/50 [00:03<00:05,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  44%|████▍     | 22/50 [00:03<00:04,  5.77it/s]\u001b[A\n",
            "DDIM Sampler:  46%|████▌     | 23/50 [00:03<00:04,  5.89it/s]\u001b[A\n",
            "DDIM Sampler:  48%|████▊     | 24/50 [00:04<00:04,  5.54it/s]\u001b[A\n",
            "DDIM Sampler:  50%|█████     | 25/50 [00:04<00:04,  5.71it/s]\u001b[A\n",
            "DDIM Sampler:  52%|█████▏    | 26/50 [00:04<00:04,  5.90it/s]\u001b[A\n",
            "DDIM Sampler:  54%|█████▍    | 27/50 [00:04<00:03,  6.00it/s]\u001b[A\n",
            "DDIM Sampler:  56%|█████▌    | 28/50 [00:04<00:03,  6.06it/s]\u001b[A\n",
            "DDIM Sampler:  58%|█████▊    | 29/50 [00:04<00:03,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  60%|██████    | 30/50 [00:04<00:03,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  62%|██████▏   | 31/50 [00:05<00:03,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  64%|██████▍   | 32/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  66%|██████▌   | 33/50 [00:05<00:02,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  68%|██████▊   | 34/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  70%|███████   | 35/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  72%|███████▏  | 36/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  74%|███████▍  | 37/50 [00:06<00:02,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  76%|███████▌  | 38/50 [00:06<00:02,  5.89it/s]\u001b[A\n",
            "DDIM Sampler:  78%|███████▊  | 39/50 [00:06<00:01,  5.89it/s]\u001b[A\n",
            "DDIM Sampler:  80%|████████  | 40/50 [00:06<00:01,  6.03it/s]\u001b[A\n",
            "DDIM Sampler:  82%|████████▏ | 41/50 [00:06<00:01,  6.08it/s]\u001b[A\n",
            "DDIM Sampler:  84%|████████▍ | 42/50 [00:06<00:01,  6.10it/s]\u001b[A\n",
            "DDIM Sampler:  86%|████████▌ | 43/50 [00:07<00:01,  5.92it/s]\u001b[A\n",
            "DDIM Sampler:  88%|████████▊ | 44/50 [00:07<00:01,  5.59it/s]\u001b[A\n",
            "DDIM Sampler:  90%|█████████ | 45/50 [00:07<00:00,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  92%|█████████▏| 46/50 [00:07<00:00,  5.55it/s]\u001b[A\n",
            "DDIM Sampler:  94%|█████████▍| 47/50 [00:07<00:00,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:  96%|█████████▌| 48/50 [00:08<00:00,  5.22it/s]\u001b[A\n",
            "DDIM Sampler:  98%|█████████▊| 49/50 [00:08<00:00,  5.41it/s]\u001b[A\n",
            "DDIM Sampler: 100%|██████████| 50/50 [00:08<00:00,  5.92it/s]\n",
            "Sampling:  50%|█████     | 2/4 [00:17<00:17,  8.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (4, 4, 32, 32), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:08,  5.80it/s]\u001b[A\n",
            "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:08,  5.56it/s]\u001b[A\n",
            "DDIM Sampler:   6%|▌         | 3/50 [00:00<00:08,  5.44it/s]\u001b[A\n",
            "DDIM Sampler:   8%|▊         | 4/50 [00:00<00:08,  5.28it/s]\u001b[A\n",
            "DDIM Sampler:  10%|█         | 5/50 [00:00<00:08,  5.60it/s]\u001b[A\n",
            "DDIM Sampler:  12%|█▏        | 6/50 [00:01<00:07,  5.75it/s]\u001b[A\n",
            "DDIM Sampler:  14%|█▍        | 7/50 [00:01<00:07,  5.80it/s]\u001b[A\n",
            "DDIM Sampler:  16%|█▌        | 8/50 [00:01<00:07,  5.82it/s]\u001b[A\n",
            "DDIM Sampler:  18%|█▊        | 9/50 [00:01<00:06,  5.94it/s]\u001b[A\n",
            "DDIM Sampler:  20%|██        | 10/50 [00:01<00:06,  6.04it/s]\u001b[A\n",
            "DDIM Sampler:  22%|██▏       | 11/50 [00:01<00:06,  6.12it/s]\u001b[A\n",
            "DDIM Sampler:  24%|██▍       | 12/50 [00:02<00:06,  6.14it/s]\u001b[A\n",
            "DDIM Sampler:  26%|██▌       | 13/50 [00:02<00:05,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  28%|██▊       | 14/50 [00:02<00:05,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  30%|███       | 15/50 [00:02<00:05,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  32%|███▏      | 16/50 [00:02<00:05,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  34%|███▍      | 17/50 [00:02<00:05,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  36%|███▌      | 18/50 [00:03<00:05,  6.30it/s]\u001b[A\n",
            "DDIM Sampler:  38%|███▊      | 19/50 [00:03<00:04,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  40%|████      | 20/50 [00:03<00:04,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  42%|████▏     | 21/50 [00:03<00:04,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  44%|████▍     | 22/50 [00:03<00:04,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  46%|████▌     | 23/50 [00:03<00:04,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  48%|████▊     | 24/50 [00:03<00:04,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  50%|█████     | 25/50 [00:04<00:04,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  52%|█████▏    | 26/50 [00:04<00:03,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  54%|█████▍    | 27/50 [00:04<00:03,  6.15it/s]\u001b[A\n",
            "DDIM Sampler:  56%|█████▌    | 28/50 [00:04<00:03,  6.17it/s]\u001b[A\n",
            "DDIM Sampler:  58%|█████▊    | 29/50 [00:04<00:03,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  60%|██████    | 30/50 [00:04<00:03,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  62%|██████▏   | 31/50 [00:05<00:03,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  64%|██████▍   | 32/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  66%|██████▌   | 33/50 [00:05<00:02,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  68%|██████▊   | 34/50 [00:05<00:02,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  70%|███████   | 35/50 [00:05<00:02,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  72%|███████▏  | 36/50 [00:05<00:02,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  74%|███████▍  | 37/50 [00:06<00:02,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  76%|███████▌  | 38/50 [00:06<00:01,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  78%|███████▊  | 39/50 [00:06<00:01,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  80%|████████  | 40/50 [00:06<00:01,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  82%|████████▏ | 41/50 [00:06<00:01,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  84%|████████▍ | 42/50 [00:06<00:01,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  86%|████████▌ | 43/50 [00:07<00:01,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  88%|████████▊ | 44/50 [00:07<00:00,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  90%|█████████ | 45/50 [00:07<00:00,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  92%|█████████▏| 46/50 [00:07<00:00,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  94%|█████████▍| 47/50 [00:07<00:00,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  96%|█████████▌| 48/50 [00:07<00:00,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  98%|█████████▊| 49/50 [00:07<00:00,  6.20it/s]\u001b[A\n",
            "DDIM Sampler: 100%|██████████| 50/50 [00:08<00:00,  6.13it/s]\n",
            "Sampling:  75%|███████▌  | 3/4 [00:26<00:08,  8.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape for DDIM sampling is (4, 4, 32, 32), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "DDIM Sampler:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2%|▏         | 1/50 [00:00<00:07,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:   4%|▍         | 2/50 [00:00<00:07,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:   6%|▌         | 3/50 [00:00<00:07,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:   8%|▊         | 4/50 [00:00<00:07,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  10%|█         | 5/50 [00:00<00:07,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  12%|█▏        | 6/50 [00:00<00:06,  6.31it/s]\u001b[A\n",
            "DDIM Sampler:  14%|█▍        | 7/50 [00:01<00:06,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  16%|█▌        | 8/50 [00:01<00:06,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  18%|█▊        | 9/50 [00:01<00:06,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  20%|██        | 10/50 [00:01<00:06,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  22%|██▏       | 11/50 [00:01<00:06,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  24%|██▍       | 12/50 [00:01<00:06,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  26%|██▌       | 13/50 [00:02<00:05,  6.24it/s]\u001b[A\n",
            "DDIM Sampler:  28%|██▊       | 14/50 [00:02<00:05,  6.27it/s]\u001b[A\n",
            "DDIM Sampler:  30%|███       | 15/50 [00:02<00:05,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  32%|███▏      | 16/50 [00:02<00:05,  6.25it/s]\u001b[A\n",
            "DDIM Sampler:  34%|███▍      | 17/50 [00:02<00:05,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  36%|███▌      | 18/50 [00:02<00:05,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  38%|███▊      | 19/50 [00:03<00:05,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  40%|████      | 20/50 [00:03<00:04,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  42%|████▏     | 21/50 [00:03<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  44%|████▍     | 22/50 [00:03<00:04,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  46%|████▌     | 23/50 [00:03<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  48%|████▊     | 24/50 [00:03<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  50%|█████     | 25/50 [00:04<00:04,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  52%|█████▏    | 26/50 [00:04<00:03,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  54%|█████▍    | 27/50 [00:04<00:03,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  56%|█████▌    | 28/50 [00:04<00:03,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  58%|█████▊    | 29/50 [00:04<00:03,  6.18it/s]\u001b[A\n",
            "DDIM Sampler:  60%|██████    | 30/50 [00:04<00:03,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  62%|██████▏   | 31/50 [00:04<00:03,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  64%|██████▍   | 32/50 [00:05<00:02,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  66%|██████▌   | 33/50 [00:05<00:02,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  68%|██████▊   | 34/50 [00:05<00:02,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  70%|███████   | 35/50 [00:05<00:02,  6.29it/s]\u001b[A\n",
            "DDIM Sampler:  72%|███████▏  | 36/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  74%|███████▍  | 37/50 [00:05<00:02,  6.32it/s]\u001b[A\n",
            "DDIM Sampler:  76%|███████▌  | 38/50 [00:06<00:01,  6.34it/s]\u001b[A\n",
            "DDIM Sampler:  78%|███████▊  | 39/50 [00:06<00:01,  6.31it/s]\u001b[A\n",
            "DDIM Sampler:  80%|████████  | 40/50 [00:06<00:01,  6.31it/s]\u001b[A\n",
            "DDIM Sampler:  82%|████████▏ | 41/50 [00:06<00:01,  6.28it/s]\u001b[A\n",
            "DDIM Sampler:  84%|████████▍ | 42/50 [00:06<00:01,  6.26it/s]\u001b[A\n",
            "DDIM Sampler:  86%|████████▌ | 43/50 [00:06<00:01,  6.20it/s]\u001b[A\n",
            "DDIM Sampler:  88%|████████▊ | 44/50 [00:07<00:00,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  90%|█████████ | 45/50 [00:07<00:00,  6.19it/s]\u001b[A\n",
            "DDIM Sampler:  92%|█████████▏| 46/50 [00:07<00:00,  6.21it/s]\u001b[A\n",
            "DDIM Sampler:  94%|█████████▍| 47/50 [00:07<00:00,  6.22it/s]\u001b[A\n",
            "DDIM Sampler:  96%|█████████▌| 48/50 [00:07<00:00,  6.23it/s]\u001b[A\n",
            "DDIM Sampler:  98%|█████████▊| 49/50 [00:07<00:00,  6.24it/s]\u001b[A\n",
            "DDIM Sampler: 100%|██████████| 50/50 [00:08<00:00,  6.24it/s]\n",
            "Sampling: 100%|██████████| 4/4 [00:34<00:00,  8.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your samples are ready and waiting four you here: \n",
            "outputs/txt2img-samples \n",
            "Enjoy.\n"
          ]
        }
      ],
      "source": [
        "import argparse, os, sys, glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm import tqdm, trange\n",
        "from einops import rearrange\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "\n",
        "\n",
        "def load_model_from_config(config, ckpt, verbose=False):\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    pl_sd = torch.load(ckpt, map_location=\"cuda\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    model = instantiate_from_config(config.model)\n",
        "    m, u = model.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "args = ['--prompt', 'a virus monster is playing guitar, oil on canvas', '--ddim_eta', '0.0', '--n_samples', '4', '--n_iter', '4', '--scale', '5.0',  '--ddim_steps', '50']\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--prompt\",\n",
        "    type=str,\n",
        "    nargs=\"?\",\n",
        "    default=\"a painting of a virus monster playing guitar\",\n",
        "    help=\"the prompt to render\"\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--outdir\",\n",
        "    type=str,\n",
        "    nargs=\"?\",\n",
        "    help=\"dir to write results to\",\n",
        "    default=\"outputs/txt2img-samples\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--ddim_steps\",\n",
        "    type=int,\n",
        "    default=200,\n",
        "    help=\"number of ddim sampling steps\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--plms\",\n",
        "    action='store_true',\n",
        "    help=\"use plms sampling\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--ddim_eta\",\n",
        "    type=float,\n",
        "    default=0.0,\n",
        "    help=\"ddim eta (eta=0.0 corresponds to deterministic sampling\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--n_iter\",\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help=\"sample this often\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--H\",\n",
        "    type=int,\n",
        "    default=256,\n",
        "    help=\"image height, in pixel space\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--W\",\n",
        "    type=int,\n",
        "    default=256,\n",
        "    help=\"image width, in pixel space\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--n_samples\",\n",
        "    type=int,\n",
        "    default=4,\n",
        "    help=\"how many samples to produce for the given prompt\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--scale\",\n",
        "    type=float,\n",
        "    default=5.0,\n",
        "    help=\"unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))\",\n",
        ")\n",
        "opt = parser.parse_args(args)\n",
        "\n",
        "\n",
        "config = OmegaConf.load(\"configs/latent-diffusion/txt2img-1p4B-eval.yaml\")  # TODO: Optionally download from same location as ckpt and chnage this logic\n",
        "model = load_model_from_config(config, \"models/ldm/text2img-large/model.ckpt\")  # TODO: check path\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "if opt.plms:\n",
        "    sampler = PLMSSampler(model)\n",
        "else:\n",
        "    sampler = DDIMSampler(model)\n",
        "\n",
        "os.makedirs(opt.outdir, exist_ok=True)\n",
        "outpath = opt.outdir\n",
        "\n",
        "prompt = opt.prompt\n",
        "\n",
        "\n",
        "sample_path = os.path.join(outpath, \"samples\")\n",
        "os.makedirs(sample_path, exist_ok=True)\n",
        "base_count = len(os.listdir(sample_path))\n",
        "\n",
        "all_samples=list()\n",
        "with torch.no_grad():\n",
        "    with model.ema_scope():\n",
        "        uc = None\n",
        "        if opt.scale != 1.0:\n",
        "            uc = model.get_learned_conditioning(opt.n_samples * [\"\"])\n",
        "        for n in trange(opt.n_iter, desc=\"Sampling\"):\n",
        "            c = model.get_learned_conditioning(opt.n_samples * [prompt])\n",
        "            shape = [4, opt.H//8, opt.W//8]\n",
        "            samples_ddim, _ = sampler.sample(S=opt.ddim_steps,\n",
        "                                              conditioning=c,\n",
        "                                              batch_size=opt.n_samples,\n",
        "                                              shape=shape,\n",
        "                                              verbose=False,\n",
        "                                              unconditional_guidance_scale=opt.scale,\n",
        "                                              unconditional_conditioning=uc,\n",
        "                                              eta=opt.ddim_eta)\n",
        "\n",
        "            x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
        "            x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, min=0.0, max=1.0)\n",
        "\n",
        "            for x_sample in x_samples_ddim:\n",
        "                x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
        "                Image.fromarray(x_sample.astype(np.uint8)).save(os.path.join(sample_path, f\"{base_count:04}.png\"))\n",
        "                base_count += 1\n",
        "            all_samples.append(x_samples_ddim)\n",
        "\n",
        "\n",
        "# additionally, save as grid\n",
        "grid = torch.stack(all_samples, 0)\n",
        "grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
        "grid = make_grid(grid, nrow=opt.n_samples)\n",
        "\n",
        "# to image\n",
        "grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
        "Image.fromarray(grid.astype(np.uint8)).save(os.path.join(outpath, f'{prompt.replace(\" \", \"-\")}.png'))\n",
        "\n",
        "print(f\"Your samples are ready and waiting four you here: \\n{outpath} \\nEnjoy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM4fitWu3-5f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KNdpRym3-7o"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXQyq9D13-9-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwVrq-4g3-_m"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0522_latent-diffusion_easystart.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}